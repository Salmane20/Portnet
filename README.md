# PORTNET - Syst√®me de D√©tection de Fraude

## üöÄ Aper√ßu

PORTNET est une application web moderne con√ßue pour la d√©tection de fraude dans les documents d'importation et les formulaires r√©glementaires. Elle utilise l'intelligence artificielle et le machine learning pour analyser et d√©tecter les anomalies dans les documents commerciaux.

## üõ† Stack Technique

### Frontend
- **Framework Principal**: React 18 avec TypeScript
- **Routage**: React Router v6
- **Styling**: 
  - Tailwind CSS
  - Shadcn/ui pour les composants
  - Framer Motion pour les animations
- **State Management**: React Query
- **Charts & Visualisations**: Recharts

### Backend & API
- **API IA**: Google Gemini Pro
- **Authentification**: JWT (pr√©par√© pour l'impl√©mentation)
- **API Documentation**: OpenAPI/Swagger (pr√©vu)

### DevOps & D√©ploiement
- **Build Tool**: Vite
- **H√©bergement**: Vercel
- **CI/CD**: Vercel CI/CD Pipeline
- **Environnement**: Node.js

## üîß Installation

1. Clonez le repository
```bash
git clone https://github.com/votre-username/portnet.git
cd portnet
```

2. Installez les d√©pendances
```bash
npm install
```

3. Configurez les variables d'environnement
```bash
cp .env.example .env.local
```
Ajoutez votre cl√© API Gemini dans le fichier .env.local :
```
VITE_GEMINI_API_KEY=votre_cl√©_api
```

4. Lancez l'application en mode d√©veloppement
```bash
npm run dev
```

## ü§ñ Impl√©mentation du Mod√®le ML pour la D√©tection de Fraude

### Architecture Recommand√©e

1. **Pr√©traitement des Documents**
   - OCR (Optical Character Recognition) pour extraire le texte des documents scann√©s
   - NLP (Natural Language Processing) pour normaliser et structurer les donn√©es
   - Extraction d'entit√©s nomm√©es pour identifier les informations cl√©s

2. **Feature Engineering**
   - Extraction des caract√©ristiques num√©riques et cat√©gorielles
   - Cr√©ation de features temporelles pour d√©tecter les anomalies de s√©quence
   - Analyse des relations entre entit√©s commerciales

3. **Mod√®le de D√©tection**
   - **Approche Hybride**:
     - Mod√®le supervis√© pour les patterns connus de fraude
     - D√©tection d'anomalies non supervis√©e pour les nouveaux types de fraude
     - Syst√®me de r√®gles m√©tier pour les v√©rifications r√©glementaires

4. **Composants du Mod√®le**:
   ```python
   # Exemple d'architecture recommand√©e
   class FraudDetectionSystem:
       def __init__(self):
           self.document_processor = DocumentProcessor()
           self.feature_extractor = FeatureExtractor()
           self.supervised_model = SupervisedDetector()
           self.anomaly_detector = AnomalyDetector()
           self.rules_engine = BusinessRulesEngine()

       def process_document(self, document):
           # Extraction et pr√©traitement
           text = self.document_processor.extract_text(document)
           features = self.feature_extractor.extract_features(text)

           # Analyse multi-niveaux
           supervised_score = self.supervised_model.predict(features)
           anomaly_score = self.anomaly_detector.detect(features)
           rules_violations = self.rules_engine.check(features)

           return self.combine_scores(supervised_score, anomaly_score, rules_violations)
   ```

### Mod√®les Recommand√©s

1. **D√©tection Supervis√©e**:
   - XGBoost ou LightGBM pour leur performance sur les donn√©es structur√©es
   - BERT ou RoBERTa fine-tun√© pour l'analyse textuelle
   - R√©seaux de neurones pour la d√©tection de motifs complexes

2. **D√©tection d'Anomalies**:
   - Isolation Forest pour les anomalies ponctuelles
   - LSTM Autoencoders pour les anomalies s√©quentielles
   - One-Class SVM pour la d√©tection de nouveaut√©s

3. **R√®gles M√©tier**:
   - Syst√®me expert bas√© sur les r√®gles du domaine
   - V√©rifications de coh√©rence des donn√©es
   - Validation des contraintes r√©glementaires

### Pipeline d'Entra√Ænement

```python
# Exemple de pipeline d'entra√Ænement
def train_fraud_detection_model(data):
    # Pr√©traitement
    preprocessed_data = preprocess_documents(data)
    features = extract_features(preprocessed_data)

    # Division des donn√©es
    train_data, test_data = train_test_split(features, test_size=0.2)

    # Entra√Ænement des mod√®les
    supervised_model.train(train_data)
    anomaly_detector.fit(train_data)
    rules_engine.update_rules(domain_rules)

    # Validation
    evaluate_model(test_data)
```

### M√©triques d'√âvaluation

- Precision et Recall pour la d√©tection de fraude
- AUC-ROC pour la performance globale
- F1-Score pour l'√©quilibre entre pr√©cision et rappel
- Temps de traitement par document
- Taux de faux positifs et faux n√©gatifs

## üìà Maintenance et Am√©lioration Continue

1. **Collecte de Donn√©es**:
   - Mise en place d'un syst√®me de feedback
   - Annotation continue des nouveaux cas
   - Enrichissement de la base d'apprentissage

2. **Monitoring**:
   - Suivi des performances en production
   - D√©tection de drift des donn√©es
   - Alertes sur les anomalies syst√®me

3. **Mise √† Jour du Mod√®le**:
   - Retraining p√©riodique
   - Ajustement des hyperparam√®tres
   - Int√©gration des nouveaux patterns de fraude

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## ü§ù Contribution

Les contributions sont les bienvenues ! Consultez `CONTRIBUTING.md` pour les directives de contribution.

## üìû Support

Pour toute question ou assistance :
- Email: contact@portnet.ma
- Site web: www.portnet.ma
- Support technique: support@portnet.ma
